{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference of subgrid forcing via neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, run the following. When prompted, choose a model among the list by providing its integer id (first column on the left). Note that this usually takes quite a long time to run (I don't know why but the kernel takes very long to start it seems, this is not related to the code being run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '../../src/gz21_ocean_momentum'))\n",
    "from analysis.utils import view_predictions, DisplayMode, plot_dataset\n",
    "from utils import select_run, select_experiment\n",
    "from analysis.utils import play_movie\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import xarray as xr\n",
    "time = 50\n",
    "\n",
    "# Prompts the user to select a trained model\n",
    "mlflow.set_tracking_uri(os.path.join(os.getcwd(), '../../mlruns'))\n",
    "cols = ['params.model_cls_name', 'params.loss_cls_name']\n",
    "exp_id, _ =select_experiment()\n",
    "run = select_run(sort_by='metrics.test loss', cols=cols, experiment_ids=[exp_id,])\n",
    "\n",
    "# Display some info about the train and validation sets for this run\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model output dataset\n",
    "client = MlflowClient()\n",
    "run_id = run['run_id']\n",
    "data_id = 0\n",
    "output_file = client.download_artifacts(run_id, \n",
    "                                        f'model_output/test_output{data_id}')\n",
    "model_output = xr.open_zarr(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = client.download_artifacts(run['params.run_id'].split('/')[0], 'forcing')\n",
    "raw_data = xr.open_zarr(raw_data)\n",
    "raw_datasets = load_training_datasets(raw_data, 'training_subdomains.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_datasets[0]\n",
    "data['time_index'] = xr.DataArray(np.arange(len(data.coords['time'])),\n",
    "                                       dims = ('time',),\n",
    "                                       coords = {'time' : data['time']})\n",
    "data = data.swap_dims({'time' : 'time_index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "plot_dataset(data[['usurf', 'vsurf']].isel(xu_ocean=randint(0, len(data['xu_ocean'])),\n",
    "                                           yu_ocean=randint(0, len(data['yu_ocean']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(data[['usurf', 'vsurf']].mean(dim='time_index'))\n",
    "_ = plt.suptitle('Average mean flow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mse = client.get_metric_history(run_id, 'train loss')\n",
    "test_mse = client.get_metric_history(run_id, 'test loss')\n",
    "train_mse = np.array([el.value for el in train_mse])\n",
    "test_mse = np.array([el.value for el in test_mse])\n",
    "plt.figure(figsize = (18, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_mse)\n",
    "plt.plot(test_mse)\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(('Train MSE', 'Test MSE'))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(10*np.log10(train_mse + 3.5))\n",
    "plt.plot(10*np.log10(test_mse + 3.5))\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylabel(r'$10 \\times \\log_{10} \\ MSE$')\n",
    "plt.legend(('Train MSE', 'Test MSE'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train loss and the test loss initially decrease steeply with the number of epochs (each epoch has around 600 samples and our number of parameters is not that high as we only use convolutional layers plus a final locally connected layer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation data for this dataset is available in the form of a dataset. Run the following to add a time index and print the model_output dataset. The variables u_surf and v_surf are the surface velocity components that are used as input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['time_index'] = xr.DataArray(np.arange(len(model_output.coords['time'])),\n",
    "                                       dims = ('time',),\n",
    "                                       coords = {'time' : model_output['time']})\n",
    "model_output = model_output.swap_dims({'time' : 'time_index'})\n",
    "model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataset of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds=xr.Dataset(dict(a=xr.DataArray([1,2,3], dims=('x',))), coords=dict(x=[5, 12, 13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.DataArray([1,2,3], coords=dict(x=[1,2,5]), dims=test_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['S_xscale'] = 1 / (model_output['S_xscale'])\n",
    "model_output['S_yscale'] = 1 / (model_output['S_yscale'])\n",
    "errors_x = model_output['S_xpred'] - model_output['S_x']\n",
    "errors_y = model_output['S_ypred'] - model_output['S_y']\n",
    "errors_x_n = errors_x / model_output['S_xscale']\n",
    "errors_y_n = errors_y / model_output['S_yscale']\n",
    "mse_x = (errors_x**2).mean(dim='time_index')\n",
    "mse_y = (errors_y**2).mean(dim='time_index')\n",
    "mse_time = ((errors_x + errors_y)**2).mean(dim='latitude').mean(dim='longitude')\n",
    "mse_time_n = ((errors_x_n + errors_y_n)**2).mean(dim='latitude').mean(dim='longitude')\n",
    "errors_ds = xr.Dataset({'S_x (error)' : errors_x, 'S_y (error)' : errors_y, \n",
    "                        'S_x (mse)' : mse_x, 'S_y (mse)' : mse_y,\n",
    "                        'S_x (normalised error)' : errors_x_n,\n",
    "                        'S_y (normalised error)' : errors_y_n,\n",
    "                        'mse (time)' : mse_time,\n",
    "                         'mse (time, normalized)': mse_time_n})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(model_output[['u_surf', 'v_surf', 'S_x', 'S_y', 'S_xpred', 'S_ypred', 'S_xscale', 'S_yscale']], plot_type='hist', bins=np.arange(-5,5, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(model_output)).max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot a snapshot corresponding to a random day from our test data. The first row correspond to the two components of the surface velocity field. The second row correspond to the two components of the \"true\" forcing. The third row corresponds to the two components of the predicted subgrid forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "n_times = len(model_output['time'])\n",
    "random_time = randint(340, 500)\n",
    "#random_time=301\n",
    "plot_dataset(model_output.isel(time_index=random_time)[['u_surf', 'v_surf', 'S_x', 'S_y', 'S_xpred', 'S_ypred', \n",
    "                                                         'S_xscale', 'S_yscale']],\n",
    "            vmin = [-2]*6 + [-0.0, 0.0], vmax = [2]*6+[1, 1])\n",
    "print(random_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of true vs pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['rez'] = (model_output['S_xpred'] - model_output['S_x']) / model_output['S_xscale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "def func(x):\n",
    "    return np.power(x, 3) / 100\n",
    "def func2(x):\n",
    "    return x\n",
    "with ProgressBar():\n",
    "    groups = model_output.groupby_bins('S_xpred', func(np.arange(-10, 10.1, 0.25)))\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    m = groups.apply(lambda x: x.mean(skipna=True)).compute()\n",
    "    s = groups.apply(lambda x: x.std(skipna=True)).compute()\n",
    "    sup = groups.apply(lambda x: x.max(skipna=True)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(m['S_xpred'], m['S_x'])\n",
    "plt.plot(m['S_xpred'], m['S_xscale'])\n",
    "plt.plot(m['S_xpred'], s['S_x'])\n",
    "plt.plot(m['S_xpred'], sup['S_xscale'])\n",
    "plt.plot(m['S_xpred'], m['rez'])\n",
    "plt.plot(np.arange(-15, 15), np.arange(-15, 15))\n",
    "plt.legend(('m S_x', 'm S_xscale', 's S_x', 'sup S_xscale', 'm rez'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "plt.figure()\n",
    "with ProgressBar():\n",
    "    for i, g in enumerate(groups):\n",
    "        if g[0].left < -4:\n",
    "            continue\n",
    "        g[1]['S_x'].plot.hist(bins=np.arange(-20, 20, 0.25))\n",
    "        g[1]['S_xpred'].plot.hist(bins=np.arange(-20, 20, 0.25), alpha=0.5)\n",
    "        plt.legend(('truth', 'pred'))\n",
    "        plt.title(str(g[0].left) + ' -> ' + str(g[0].right))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = dataset_to_movie(model_output.isel(time_index=slice(0, 200))[['u_surf', 'v_surf', 'S_x', 'S_xpred', 'S_y', 'S_ypred']],\n",
    "                      interval = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = ani.to_html5_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a quick analysis by showing the MSE across time at all spatial points of our domain. We also plot the mean ampltiude of the velocity components as well as its variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(errors_ds[['S_x (mse)', 'S_y (mse)']], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_dataset(model_output[['u_surf', 'v_surf']].mean(dim='time_index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(model_output[['u_surf', 'v_surf']].std(dim='time_index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem far fetched to associate the larger errors in the predicted subgrid forcing with the larger variance of the velocity field, at least for the NW area.\n",
    "We could look at the time series of the predictions for the specific areas with larger errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 30))\n",
    "long = -172\n",
    "lat = -34\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "time = slice(0, 400)\n",
    "model_output['S_y'].isel(time_index=time).sel(longitude=long, latitude=lat, method='nearest').plot(linewidth=3)\n",
    "model_output['S_ypred'].isel(time_index=time).sel(longitude=long, latitude=lat, method='nearest').plot(linewidth=3)\n",
    "uB = model_output['S_ypred'] + 1.96 * model_output['S_yscale']\n",
    "lB = model_output['S_ypred'] - 1.96 * model_output['S_yscale']\n",
    "uB.isel(time_index=time).sel(longitude=long, latitude=lat, method='nearest').plot(linestyle='--',color='gray')\n",
    "lB.isel(time_index=time).sel(longitude=long, latitude=lat, method='nearest').plot(linestyle='--',color='gray')\n",
    "plt.ylim(-1, 1)\n",
    "plt.legend(('True forcing', 'Inferred forcing', '95% confidence interval'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the amplitude of the forcing reaches 15 stds at some point. This needs investigation. It also turns out that the same phenomenon is observed for the NW location where larger errors are seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also look at the aspect of the error through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(errors_ds['S_x (normalised error)']).isel(time_index=randint(0, 500)).plot(vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_ds['S_x (normalised error)'].sel(longitude=-172, latitude=-34, method='nearest').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((errors_ds['S_x (normalised error)'])**2).mean(dim=('longitude', 'latitude')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we look at the amplitude of the velocity field along the same dimension (time this time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(model_output[['u_surf', 'v_surf', 'S_x', 'S_y']].mean(dim='latitude').mean(dim='longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.utils import sample\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import laplace\n",
    "from scipy.stats import t\n",
    "t0 = t(6)\n",
    "errors_ds = errors_ds.sel(longitude=slice(-175, -167), latitude=slice(-36, -30))\n",
    "residuals = errors_ds[['S_x (normalised error)', 'S_y (normalised error)']].to_array().compute().data\n",
    "residuals = residuals.swapaxes(0, 1)\n",
    "s0 = sample(residuals, 5, 50)\n",
    "s1 = s0 / np.std(s0)\n",
    "plt.hist(s1[:, :, :].reshape((-1, 1)), bins = 500, density=True)\n",
    "plt.plot(np.arange(-5, 5, 0.01), norm.pdf(np.arange(-5, 5, 0.01)))\n",
    "plt.plot(np.arange(-5, 5, 0.01), laplace.pdf(np.arange(-5, 5, 0.01)))\n",
    "# plt.plot(np.arange(-5, 5, 0.01), t0.pdf(np.arange(-5, 5, 0.01)))\n",
    "\n",
    "\n",
    "plt.xlim([-7, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "t0 = t(6)\n",
    "errors = s1[:, :, :].reshape(-1, 1)\n",
    "errors = errors - np.mean(errors)\n",
    "n = errors.shape[0]\n",
    "norm_quantiles = norm.ppf(np.linspace(1/n, 1 - 1/n, n))\n",
    "sorted_errors = np.sort(errors, axis=None)\n",
    "plt.plot(norm_quantiles, norm_quantiles)\n",
    "plt.plot(norm_quantiles, sorted_errors)\n",
    "_ = plt.title('Quantile-Quantile plot of the errors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
