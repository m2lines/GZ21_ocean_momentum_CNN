{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import client\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "sys.path.insert(1, os.path.join(os.getcwd()  , '../../src/gz21_ocean_momentum'))\n",
    "from utils import select_experiment, select_run\n",
    "from analysis.utils import plot_dataset, GlobalPlotter, anomalies\n",
    "from data.pangeo_catalog import get_whole_data\n",
    "from data.xrtransforms import SeasonalStdizer, TargetedTransform, ScalingTransform\n",
    "from dask.diagnostics import ProgressBar\n",
    "from models.submodels import transform3\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "!pip install cmocean\n",
    "import cmocean\n",
    "\n",
    "cmap = cmocean.cm.balance\n",
    "cmap_balance = cmocean.cm.balance\n",
    "cmap_balance_r=cmocean.cm.balance_r\n",
    "\n",
    "cmap_amp = cmocean.cm.amp\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 4 / 1.618)\n",
    "\n",
    "uv_plotter = GlobalPlotter() \n",
    "uv_plotter.x_ticks = np.arange(-150., 151., 50)\n",
    "uv_plotter.y_ticks = np.arange(-80., 81., 20)\n",
    "\n",
    "\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URL = 'https://raw.githubusercontent.com/pangeo-data/pangeo-datastore\\\n",
    "/master/intake-catalogs/master.yaml'\n",
    "data = get_whole_data(CATALOG_URL, 0)\n",
    "grid_info = data[1]\n",
    "# mask = grid_info['wet'].coarsen(dict(xt_ocean=4, yt_ocean=4))\n",
    "# mask_ = mask.max()\n",
    "# mask_ = mask_.where(mask_ > 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_exp_name = select_experiment()\n",
    "test_exp = mlflow.get_experiment_by_name(test_exp_name)\n",
    "test_exp_id = test_exp.experiment_id\n",
    "run = select_run(experiment_ids=test_exp_id, cols=['status', 'start_time', 'params.CO2', 'params.factor',\n",
    "                                                  'params.submodel'],\n",
    "                merge=[('data-global', 'params.data_run_id', 'run_id'),\n",
    "                      ('modelsv1', 'params.model_run_id', 'run_id')])\n",
    "client_ = client.MlflowClient()\n",
    "data_file_name = client_.download_artifacts(run['params.data_run_id'], 'forcing')\n",
    "print('Data path:', data_file_name)\n",
    "data = xr.open_zarr(data_file_name)\n",
    "data = data.rename({'xu_ocean': 'longitude', 'yu_ocean': 'latitude'})\n",
    "data = data * 1e7\n",
    "pred_file_name = client_.download_artifacts(run.run_id, 'test_output_0')\n",
    "pred = xr.open_zarr(pred_file_name)\n",
    "data = data.sel(time=slice(pred.time[0], pred.time[-1])).sel(latitude=slice(pred.latitude[0], pred.latitude[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = slice(None, None, 1)\n",
    "lat= slice(-80, 80, 1)\n",
    "time_slice = slice(None, None, 1)\n",
    "\n",
    "p0 = pred['0'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "p1 = pred['1'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "p0 = np.exp(p0) / (np.exp(p0) + np.exp(p1))\n",
    "p1 = 1 - p0\n",
    "# Means\n",
    "mu0 = pred['4'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "mu1 = pred['8'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "true = data['S_x'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "# precisions\n",
    "beta0 = pred['6'].sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "beta1 = pred['10'].sel(longitude=lon, latitude=lat).isel(time=time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_complete_mask(array):\n",
    "    mask = uv_plotter.borders\n",
    "    mask2 = uv_plotter.mask\n",
    "    mask = mask.interp({k: array.coords[k] for k in ['longitude', 'latitude']})\n",
    "    mask2 = mask2.interp({k: array.coords[k] for k in ['longitude', 'latitude']})\n",
    "    array = array.where(np.isnan(mask) & (~np.isnan(mask2)))\n",
    "    array = array.sel(latitude=slice(pred['latitude'][0], pred['latitude'][-1]))\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = -129\n",
    "lat= -55\n",
    "\n",
    "p0_ = p0.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "mu0_ = mu0.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "mu1_ = mu1.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "beta0_ = beta0.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "beta1_ = beta1.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "true_ = true.sel(longitude=lon, latitude=lat, method='nearest')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(p0_)\n",
    "plt.plot(true_, '-x')\n",
    "plt.plot(mu0_, 'r')\n",
    "plt.plot(mu1_, 'k')\n",
    "plt.plot(mu0_ -1.96 * 1 / beta0_, '--r')\n",
    "plt.plot(mu0_ + 1.96 * 1 / beta0_, '--r')\n",
    "plt.plot(mu1_ - 1.96 * 1 / beta1_, '--k')\n",
    "plt.plot(mu1_ + 1.96 * 1 / beta1_, '--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 796\n",
    "n_samples = 1000000\n",
    "sel = np.random.rand(n_samples) > float(p0_.isel(time=time))\n",
    "sel = np.arange(n_samples) + sel * n_samples\n",
    "samples0 = np.random.randn(n_samples) / float(beta0_.isel(time=time)) + float(mu0_.isel(time=time))\n",
    "samples1 = np.random.randn(n_samples) / float(beta1_.isel(time=time)) + float(mu1_.isel(time=time))\n",
    "samples = np.concatenate((samples0, samples1))\n",
    "final_samples = samples[sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "print(float(true_.isel(time=time)))\n",
    "_ = plt.hist(final_samples, bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global distribution of true and simulated forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assess the goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(x, p0, mu0, beta0, mu1, beta1):\n",
    "    return p0 * norm.pdf((x - mu0) * beta0) + (1 - p0) * norm.pdf((x - mu1) * beta1)\n",
    "\n",
    "lkh = pdf(true, p0, mu0, beta0, mu1, beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(lkh.mean(dim='time'), origin='lower', vmin=0, vmax=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = slice(-40, 40)\n",
    "with ProgressBar():\n",
    "    mean_lkh = apply_complete_mask(lkh.sel(latitude=lat)).mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lkh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goodness of fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def my_transform(x ,p0, mu0, beta0, mu1, beta1):\n",
    "    cdf = lambda x: p0 * norm.cdf((x - mu0) * beta0) + (1 - p0) * norm.cdf((x - mu1) * beta1)\n",
    "    return cdf(x)\n",
    "\n",
    "v = my_transform(true, p0, mu0, beta0, mu1, beta1)\n",
    "v = v.sel(latitude=slice(-40, 40))\n",
    "v = apply_complete_mask(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(v.values.flatten(), bins=200, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.exp(np.linspace(-10, 10, 100)) / (1 + np.exp(np.linspace(-10, 10, 100)))\n",
    "\n",
    "q = np.nanquantile(v, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(quantiles, q, 'x')\n",
    "plt.plot(quantiles, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "s = norm.ppf(q)\n",
    "plt.figure()\n",
    "plt.plot(norm.ppf(quantiles),  s, 'x')\n",
    "plt.plot(norm.ppf(quantiles),  norm.ppf(quantiles))\n",
    "plt.axis([None, None, -18, None])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of simulated vs true forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_true = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_complete_mask(array):\n",
    "    mask = uv_plotter.borders\n",
    "    mask2 = uv_plotter.mask\n",
    "    mask = mask.interp({k: array.coords[k] for k in ['longitude', 'latitude']})\n",
    "    mask2 = mask2.interp({k: array.coords[k] for k in ['longitude', 'latitude']})\n",
    "    array = array.where(np.isnan(mask) & (~np.isnan(mask2)))\n",
    "    array = array.sel(latitude=slice(pred['latitude'][0], pred['latitude'][-1]))\n",
    "    return array\n",
    "\n",
    "true = apply_complete_mask(saved_true)\n",
    "\n",
    "epsilon = np.random.randn(*true.shape)\n",
    "epsilon2 = np.random.randn(*true.shape)\n",
    "bernouilli = np.random.rand(*true.shape) > p0\n",
    "simulated = bernouilli * (mu0 + epsilon / beta0) + (1 - bernouilli) * (mu1 + epsilon / beta1)\n",
    "\n",
    "simulated = apply_complete_mask(simulated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(true.values.ravel(), log=True, bins=np.arange(-20, 21, 0.5), density=True)\n",
    "_ = plt.hist(simulated.values.ravel(), log=True, bins=np.arange(-20, 21, 0.5), density=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.exp(np.linspace(-3, 3, 100)) / (1 + np.exp(np.linspace(-3, 3, 100)))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_true = np.nanquantile(true.values.ravel(), quantiles)\n",
    "q_simu = np.nanquantile(simulated.values.ravel(), quantiles)\n",
    "plt.figure()\n",
    "plt.plot(q_true, q_simu, 'x')\n",
    "plt.plot(q_true, q_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(q_true, q_simu, 'x')\n",
    "plt.plot(q_true, q_true, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantiles analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import cmocean\n",
    "mean_pred = p0 * mu0 + p1 * mu1\n",
    "plt.figure()\n",
    "plt.imshow(np.abs((mean_pred.mean(dim='time') - true.mean(dim='time'))) / true.std(dim='time'), vmin=0.01, vmax=1, norm=matplotlib.colors.LogNorm()\n",
    ", origin='lower', cmap=cmocean.cm.delta)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
