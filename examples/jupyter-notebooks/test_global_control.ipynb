{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on Global scale "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "* `ipympl` (`pip install ipympl`)\n",
    "* `cmocean` (`pip install cmocean`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce the paper figures, this notebook has to be run twice: once with CO2=1 settings and once with CO2=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook  #This option does not work in Jupyterlab\n",
    "%matplotlib widget\n",
    "\n",
    "# See https://github.com/m2lines/gz21_ocean_momentum/blob/main/docs/data.md for an explanation\n",
    "# The environment variable does not need setting if you place the credentials file at ~/.config/gcloud/application_default_credentials.json .\n",
    "\n",
    "# Or you can set it by uncommenting the below with your path to the credentials file\n",
    "# %env GOOGLE_APPLICATION_CREDENTIALS my_path/application_default_credentials.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import mlflow\n",
    "from mlflow.tracking import client\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from gz21_ocean_momentum.utils import select_experiment, select_run\n",
    "from gz21_ocean_momentum.analysis.utils import (plot_dataset, GlobalPlotter, anomalies,\n",
    "                            download_data_pred, plot_time_series, apply_complete_mask)\n",
    "from gz21_ocean_momentum.data.pangeo_catalog import get_whole_data\n",
    "from gz21_ocean_momentum.data.xrtransforms import SeasonalStdizer, TargetedTransform, ScalingTransform\n",
    "from dask.diagnostics import ProgressBar\n",
    "from models.submodels import transform3\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the plotter\n",
    "plt.rcParams[\"figure.figsize\"] = (4, 4 / 1.618)\n",
    "\n",
    "import gz21_ocean_momentum.analysis as analysis\n",
    "GlobalPlotter = analysis.utils.GlobalPlotter\n",
    "uv_plotter = GlobalPlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_plot = GlobalPlotter.plot\n",
    "\n",
    "def new_plot_func(self, name: str, *args, **kargs):\n",
    "    data = xr.Dataset({name: args[0]})\n",
    "    old_plot(self, *args, **kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This downloads some information about the grid, used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATALOG_URL = 'https://raw.githubusercontent.com/pangeo-data/pangeo-datastore\\\n",
    "/master/intake-catalogs/master.yaml'\n",
    "data = get_whole_data(CATALOG_URL, 0)\n",
    "grid_info = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mflow = False\n",
    "# If we are using mlflow, we need to select the experiment and run\n",
    "if (mflow):\n",
    "  print(\"Select the experiment of the inference run.\")\n",
    "\n",
    "  exp_id, test_exp_name = select_experiment()\n",
    "  cols=['status', 'start_time', 'params.CO2', 'params.factor',\n",
    "        'params.submodel', 'params.loss_cls_name']\n",
    "  # In the following merge parameter, the first strings in the tupels need to be the experiment names for the data run and the training run, respectively.\n",
    "  # If these are in the same experiment they can either be duplicated, or you can set merge=[].\n",
    "  # This is used to show the available runs.\n",
    "  merge=[('data', 'params.data_run_id', 'run_id'),\n",
    "        ('train', 'params.model_run_id', 'run_id')]\n",
    "  run = select_run(experiment_ids=exp_id, cols=cols, merge=merge)\n",
    "  data, pred = download_data_pred(run['params.data_run_id'], run.run_id)\n",
    "else:\n",
    "  # Otherwise we can mockup data from downloaded forcings data\n",
    "  # e.g., from HuggingFace (https://huggingface.co/datasets/gz21_ocean_momentum)\n",
    "  path = \"/Users/dorchard/Documents/iccs/gz21_ocean_momentum/forcings\"\n",
    "  data = xr.open_zarr(path)\n",
    "  pred = xr.open_zarr(path)\n",
    "  # Rename fields\n",
    "  data = data.rename({\"xu_ocean\": \"longitude\", \"yu_ocean\": \"latitude\"})\n",
    "  pred = pred.rename({\"xu_ocean\": \"longitude\", \"yu_ocean\": \"latitude\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "html = '<h2>Menu</h2>'\n",
    "html += '<a href=\"#MSE-and-R²\">MSE and R²</a> &nbsp;'\n",
    "html += '<a href=\"#Correlation-between-true-forcing-and-mean-component-of-the-prediction\"> Correlation</a> &nbsp;'\n",
    "html += '<a href=\"#Variance-of-norm-of-subgrid-momentum-forcing\">Variance of forcing</a> &nbsp;'\n",
    "html += '<a href=\"#Compare-distributions-of-true-and-stochastic-simulated-forcing\">Comparison of distributions</a> &nbsp;'\n",
    "html += '<a href=\"#QQ-plot\">QQ-plot</a> &nbsp;'\n",
    "html += '<a href=\"#Bias-analysis\">Bias analysis</a> &nbsp;'\n",
    "html += '<a href=\"#Time-series-plots\">Time series plots</a>'\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_plotter.plot(data['S_x'].isel(time=70), lon=0., projection_cls = ccrs.PlateCarree,\n",
    "                colorbar_label='m/s', cmap=cmocean.cm.delta, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the plot shown in Figure 5 of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(data, pred, longitude: float, latitude: float, time: slice,\n",
    "                     std: bool = True, true: bool = True):\n",
    "    plt.figure()\n",
    "    xs = np.arange(time.start, time.stop, time.step)\n",
    "    truth = data['S_x'].sel(longitude=longitude, latitude=latitude,\n",
    "                            method='nearest').isel(time=time)\n",
    "    pred_mean = pred['S_x'].sel(longitude=longitude, latitude=latitude,\n",
    "                                method='nearest').isel(time=time)\n",
    "    pred_std = pred['S_xscale'].sel(longitude=longitude, latitude=latitude,\n",
    "                                    method='nearest').isel(time=time)\n",
    "    if true:\n",
    "        plt.plot(xs, truth, 'darkblue')\n",
    "    plt.plot(xs, pred_mean, 'darkorange')\n",
    "    if std:\n",
    "        plt.plot(xs, pred_mean + 1.96 * pred_std, 'g--', linewidth=1)\n",
    "        plt.plot(xs, pred_mean - 1.96 * pred_std, 'g--', linewidth=1)\n",
    "    plt.ylabel(r'$1e^{-7}m/s^2$')\n",
    "    _ = plt.xlabel('days')\n",
    "\n",
    "time_slice=slice(0, 300)\n",
    "plt.rcParams[\"figure.figsize\"] = (4 * 2, 4 * 2 / 1.618)\n",
    "\n",
    "plot_time_series(data, pred, longitude=-60, latitude=30, time=time_slice, std=True, true=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('timeseries3.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('timeseriespredcontrol.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE and R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute the seasonal (monthly) means of the data. This will be used later in some of the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_vars = ['S_x', 'S_y']\n",
    "errors = pred[forcing_vars] - data[forcing_vars]\n",
    "errors_cycle = anomalies(data[forcing_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, mse is the time-mean MSE of the mean component of our predicted forcing, mse_month is the variance of the residuals of the data after removing monthly variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = (errors**2).mean(dim='time')\n",
    "mse_cycle = (errors_cycle**2).mean(dim='time')\n",
    "amplitudes = (data[forcing_vars]**2).mean(dim='time')\n",
    "\n",
    "with ProgressBar():\n",
    "    mse = mse.compute()\n",
    "    mse_cycle = mse_cycle.compute()\n",
    "    amplitudes = amplitudes.compute()\n",
    "mse['total'] = mse['S_x'] + mse['S_y']\n",
    "mse_cycle['total'] = mse_cycle['S_x'] + mse_cycle['S_y']\n",
    "amplitudes['total'] = amplitudes['S_x'] + amplitudes['S_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Figure 4a of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4*2, 4 * 2 / 1.618)\n",
    "x = uv_plotter.plot(mse['total'], lon=0., cmap=cmocean.cm.dense,\n",
    "                    colorbar_label=r'$1e^{-14}m^2/s^4$', norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('msecontrol.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('mse1pct.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R² plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Figure 4b of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "rsquared = 1 - mse / amplitudes\n",
    "rsquared_cycles = 1 - mse / mse_cycle\n",
    "mse_ratio_2 = 1 - mse_cycle / amplitudes\n",
    "uv_plotter.plot(rsquared_cycles['total'], cmap=cmocean.cm.delta, lon=0., norm=matplotlib.colors.LogNorm(vmin=0.5, vmax=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('r2_control_month.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('r2_1pctC02_month.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We limit the range to latitudes -60 to 60, and we apply a mask that discards points near continents according to the mask used in the plotter (the points shown in gray on the maps in the paper). This is why we define these quantities \"to_scalar\", in order to not account for points near continents in the computation of the scalar R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitudes = slice(-60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_to_scalar = apply_complete_mask(mse, pred, uv_plotter)\n",
    "mse_cycle_to_scalar = apply_complete_mask(mse_cycle, pred, uv_plotter)\n",
    "amplitudes_to_scalar = apply_complete_mask(amplitudes, pred, uv_plotter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    mse_scalar = mse_to_scalar.sel(latitude=latitudes).sum().compute()\n",
    "    mse_cycle_scalar = mse_cycle_to_scalar.sel(latitude=latitudes).sum().compute()\n",
    "    amplitudes_scalar = amplitudes_to_scalar.sel(latitude=latitudes).sum().compute()\n",
    "    rsquared_scalar_cycle = 1 - mse_scalar / mse_cycle_scalar\n",
    "    rsquared_scalar = 1 - mse_scalar / amplitudes_scalar\n",
    "print(rsquared_scalar)\n",
    "print(rsquared_scalar_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between true forcing and mean component of the prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_vars = ['S_x', 'S_y']\n",
    "data_anomaly = anomalies(data[forcing_vars])\n",
    "pred_anomaly = anomalies(pred[forcing_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_data = data_anomaly.std(dim='time')\n",
    "std_pred = pred_anomaly.std(dim='time')\n",
    "corr = ((data_anomaly * pred_anomaly).mean(dim='time') - data_anomaly.mean(dim='time') * pred_anomaly.mean(dim='time')) / (std_data * std_pred)\n",
    "# corr_s_y = xr.corr(data.S_y, pred.S_y, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    corr = corr.compute()\n",
    "    # corr_s_y = corr_s_y.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_plotter.plot(corr['S_x'], vmin=0.7, vmax=1., lon=0., cmap=cmocean.cm.balance_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('corr_X_1pct.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance of norm of subgrid momentum forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_S = np.sqrt(data['S_x']**2 + data['S_y']**2)\n",
    "norm_Spred = np.sqrt(pred['S_x']**2 + pred['S_y']**2)\n",
    "var_norm_S = norm_S.var(dim='time')\n",
    "var_norm_Spred = norm_Spred.var(dim='time')\n",
    "with ProgressBar():\n",
    "    var_norm_S = var_norm_S.compute()\n",
    "    var_norm_Spred = var_norm_Spred.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_plotter.plot(var_norm_S, cmap=cmocean.cm.dense, lon=0., colorbar_label=r'$1e^{-14}m^2s^{-4}$', norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=10,))\n",
    "uv_plotter.plot(var_norm_Spred, cmap=cmocean.cm.dense, lon=0., colorbar_label=r'$1e^{-14}m^2s^{-4}$', norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('variance_forcing_control.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('variance_forcing_control_pred.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('variance_forcing_control_pred.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare distributions of true and stochastic simulated forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_vars = ['S_x', 'S_y']\n",
    "scale_vars = ['S_xscale', 'S_yscale']\n",
    "\n",
    "pred_ = apply_complete_mask(pred, pred, uv_plotter)\n",
    "pred_scale = pred_[scale_vars].rename(dict(S_xscale='S_x', S_yscale='S_y'))\n",
    "pred_ = pred_[forcing_vars]\n",
    "data_ = apply_complete_mask(data[forcing_vars], pred, uv_plotter)\n",
    "\n",
    "# Subsample the data\n",
    "time_slice = slice(None, None, 1)\n",
    "lon_slice = slice(None, None, 2)\n",
    "lat_slice = slice(-60, 60, 2)\n",
    "pred_ = pred_.sel(longitude=lon_slice, latitude=lat_slice).isel(time=time_slice)\n",
    "pred_scale = pred_scale.sel(longitude=lon_slice, latitude=lat_slice).isel(time=time_slice)\n",
    "data_ = data_.sel(longitude=lon_slice, latitude=lat_slice).isel(time=time_slice)\n",
    "\n",
    "# Standardized residuals\n",
    "residuals = (data_ - pred_) / pred_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.isnan(data_['S_x']) == np.isnan(pred_['S_x'])), \"Not the same number of points!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a stochastic simulation of the forcing given the parameters of the Gaussian distribution at each location and each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple(pred_.dims.values())\n",
    "epsilons = dict(x=np.random.randn(*shape), y=np.random.randn(*shape))\n",
    "epsilons = xr.Dataset(dict(S_x=(pred_.dims, epsilons['x']), S_y=(pred_.dims, epsilons['y'])))\n",
    "pred_stochastic = pred_ + pred_scale * epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-20, 21, 1)\n",
    "\n",
    "# assert np.all(np.isnan(data_['S_x']) == np.isnan(pred_stochastic['S_x'])), \"Not the same number of points!\"\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "with ProgressBar():\n",
    "    plt.hist(np.ravel(data_['S_x']), bins=bins, density=True, log=True, alpha=0.5, color='purple')\n",
    "    plt.hist(np.ravel(pred_stochastic['S_x']), bins=bins, density=True, log=True, alpha=0.5, color='green')\n",
    "plt.title('Zonal component')\n",
    "plt.xlabel(r'$1e^{-7}m/s^2$')\n",
    "plt.ylabel('log density')\n",
    "plt.subplot(122)\n",
    "with ProgressBar():\n",
    "    plt.hist(np.ravel(data_['S_y']), bins=bins, density=True, log=True, alpha=0.5, color='purple')\n",
    "    plt.hist(np.ravel(pred_stochastic['S_y']), bins=bins, density=True, log=True, alpha=0.5, color='green')\n",
    "plt.title('Meridional component')\n",
    "plt.xlabel(r'$1e^{-7}m/s^2$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('forcing_dist_control.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "bins=np.arange(-6, 6, 0.025)\n",
    "from scipy.stats import norm\n",
    "with ProgressBar():\n",
    "    plt.subplot(121)\n",
    "    plt.hist(np.ravel(residuals['S_x'].compute()), bins=bins, density=True, color='orange')\n",
    "    plt.plot(bins, (norm.pdf(bins)), 'r')\n",
    "    plt.title('Meridional component')\n",
    "    plt.subplot(122)\n",
    "    plt.hist(np.ravel(residuals['S_y'].compute()), bins=bins, density=True, color='orange')\n",
    "    plt.plot(bins, (norm.pdf(bins)), 'r')\n",
    "    plt.title('Zonal component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('normalized_residuals_ditribution.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QQ plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = np.exp(np.linspace(-5, 5, 100)) / (1 + np.exp(np.linspace(-5, 5, 100)))\n",
    "quantiles = np.linspace(0.01, 0.99, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    quantiles_x = np.nanquantile(residuals['S_x'].compute(), quantiles)\n",
    "    quantiles_y = np.nanquantile(residuals['S_y'].compute(), quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, cauchy, t\n",
    "quantiles_norm = norm.ppf(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "reference = quantiles_norm\n",
    "plt.subplot(121)\n",
    "plt.plot(reference, quantiles_x, 'x')\n",
    "plt.plot(reference, reference, 'g')\n",
    "plt.axis([None, None, -5, 5])\n",
    "plt.title('Zonal component')\n",
    "plt.subplot(122)\n",
    "plt.plot(reference, quantiles_y, 'x')\n",
    "plt.plot(reference, reference, 'g')\n",
    "plt.axis([None, None, -5, 5])\n",
    "plt.title('Meridional component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('normalized_residuals_qq.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IGNORE THIS) Another way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "lon = slice(None, None, 1)\n",
    "lat= slice(-40, 40, 1)\n",
    "time_slice = slice(None, 1000, 1)\n",
    "\n",
    "true = apply_complete_mask(data['S_x'])\n",
    "pred_mean = apply_complete_mask(pred['S_x'])\n",
    "pred_std = apply_complete_mask(pred['S_xscale'])\n",
    "\n",
    "def my_transform(x , mean, precision):\n",
    "    cdf = lambda x: norm.cdf((x - mean) * precision)\n",
    "    return cdf(x)\n",
    "\n",
    "v = xr.apply_ufunc(my_transform, true, pred_mean, 1 / pred_std,\n",
    "                  dask='parallelized', output_dtypes=[np.float64, ])\n",
    "residuals = (true - pred_mean) / pred_std\n",
    "residuals = residuals.sel(longitude=lon, latitude=lat).isel(time=time_slice)\n",
    "v = v.sel(longitude=lon, latitude=lat).isel(time=time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    q2 = np.nanquantile(residuals, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_quantiles = norm.ppf(quantiles)\n",
    "plt.figure()\n",
    "plt.plot(norm_quantiles, q2)\n",
    "plt.plot(norm_quantiles, norm_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.nanquantile(v, quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(quantiles, q, 'x')\n",
    "plt.plot(quantiles, quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (IGNORE THIS) Likelihood plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "lon = slice(None, None, 1)\n",
    "lat= slice(-80, 80, 1)\n",
    "time_slice = slice(None, None, 1)\n",
    "\n",
    "true = data['S_x'].isel(time=time_slice)\n",
    "pred_mean = pred['S_x'].isel(time=time_slice)\n",
    "pred_std = pred['S_xscale'].isel(time=time_slice)\n",
    "\n",
    "residuals = (true - pred_mean) / pred_std\n",
    "log_lkh = xr.apply_ufunc(lambda x: np.log(norm.pdf(x)), residuals, dask='parallelized', output_dtypes=[np.float64,])\n",
    "with ProgressBar():\n",
    "    log_lkh = log_lkh.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_plotter.margin=10\n",
    "uv_plotter.plot(-log_lkh.mean(dim='time'), vmin=0, vmax=2.5)\n",
    "apply_complete_mask(-log_lkh, pred, uv_plotter).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat= slice(-40, 40, 1)\n",
    "\n",
    "with ProgressBar():\n",
    "    lkh_mean = lkh.sel(latitude=lat).isel(time=time_slice).mean().compute()\n",
    "lkh_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_vars = ['S_x', 'S_y']\n",
    "errors = pred[forcing_vars] - data[forcing_vars]\n",
    "map_errors = errors.mean(dim='time')\n",
    "with ProgressBar():\n",
    "    map_errors = map_errors.compute()\n",
    "    absolute = (abs(data[forcing_vars])).mean(dim='time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_bias = (map_errors / absolute).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    uv_plotter.plot(abs(relative_bias['S_x']), cmap=cmocean.cm.delta, lon=0., vmin=0.01, vmax=1, norm=matplotlib.colors.LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('relative_bias_control.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (4*2, 4*2 / 1.618)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = [(-60, 30), (-104, -20), (-129, 29)]\n",
    "\n",
    "plot_time_series(data, pred, *points[1], slice(0, 300), std=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('timeseries_quescient.jpg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (IGNORE THIS) Comparison of quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.base import QuantileCompare\n",
    "\n",
    "with ProgressBar():\n",
    "    qq = QuantileCompare()\n",
    "    qq.quantiles = [0.5, 0.25, 0.5, 0.75, 0.95]\n",
    "    qq.data = ((pred['S_x']-data['S_x']) / pred['S_xscale']).isel(time=slice(None, None, 1)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    q_0_75 = qq.data_quantiles[0.75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "norm.ppf(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cmocean\n",
    "cmap = cmocean.cm.balance\n",
    "uv_plotter.plot(np.abs(q_0_75 - 0.6745) < 0.05, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv_plotter.plot(data['S_x'].isel(time=0), cmap=cmap_balance, vmin=-2, vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((data['S_x'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800))).data)\n",
    "plt.plot((pred['S_xpred'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800))).data)\n",
    "plt.plot((pred['S_xpred'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800)) + 1.96 * pred['S_xscale'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800))).data, '--')\n",
    "plt.plot((pred['S_xpred'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800)) - 1.96 * pred['S_xscale'].sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800))).data, '--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = qq.data.sel(longitude=-140, latitude=30, method='nearest').isel(time=slice(0, 800)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(r, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.ravel(q_0_25.data), bins=np.arange(-2, 2, 0.1))\n",
    "plt.title('Histogram of 0.25 quantiles of normalized residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(r.data, [0.25, 0.5, 0.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(q_0_5).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshot of the forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "cmap = cmocean.cm.balance\n",
    "s_x = v\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(-100.))\n",
    "mesh_x, mesh_y = np.meshgrid(s_x['longitude'], s_x['latitude'])\n",
    "mesh_x = mesh_x + 360\n",
    "ax.pcolormesh(mesh_x, mesh_y, s_x.values, vmin=-4, vmax=4, transform = ccrs.PlateCarree(), cmap=cmap, alpha=1)\n",
    "mesh_x, mesh_y = np.meshgrid(borders['longitude'], borders['latitude'])\n",
    "mesh_x = mesh_x + 360\n",
    "ax.pcolormesh(mesh_x, mesh_y, borders * 1., transform=ccrs.PlateCarree(), alpha=0.1)\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "ax.set_xticks(np.arange(-180, 181, 20))\n",
    "ax.set_yticks(np.arange(-80,81, 20))\n",
    "#ax.set_extent([-20, 20, -20, 20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "cmap = cmocean.cm.amp\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "try:\n",
    "    del video\n",
    "except:\n",
    "    pass\n",
    "\n",
    "uv_plotter.x_ticks = None\n",
    "uv_plotter.y_ticks = None\n",
    "\n",
    "def animate(i):\n",
    "    print(i)\n",
    "    v = pred['S_xscale'].isel(time=i)\n",
    "    uv_plotter.plot(v, projection_cls = ccrs.Orthographic, lon=(i/5)%360, cmap=cmap, vmin=0, vmax=2, animated=True)\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames = 500, interval = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['animation.embed_limit'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('forcing_pred_mean.mp4', fps=60, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "video = ani.to_html5_video()\n",
    "HTML(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = (merged['S_xpred'] - merged['S_x']) / merged['S_xscale']\n",
    "d = (e**2).mean(dim='time').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = abs(d-1)\n",
    "d_ = d_.interp(mask_.coords)\n",
    "d_ = xr.where(borders, -1000, d_)\n",
    "d_ = xr.where(mask__, d_, np.nan)\n",
    "d_ = d_.interp(latitude = np.arange(-80, 80, 0.1), longitude = np.arange(-279.9, 80.1, 0.1))\n",
    "d_['longitude'] = d_['longitude'] + 100.\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "d_.plot.imshow(x='longitude', y='latitude', ax=ax, vmin=0, vmax=2, cmap=cmap,\n",
    "                        transform = ccrs.PlateCarree(-100.))\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "x_ticks = plt.xticks(np.arange(-180, 181, 20))\n",
    "y_ticks = plt.yticks(np.arange(-80, 81, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
